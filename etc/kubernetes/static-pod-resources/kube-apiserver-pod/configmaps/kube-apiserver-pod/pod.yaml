{
  "kind": "Pod",
  "apiVersion": "v1",
  "metadata": {
    "name": "kube-apiserver",
    "namespace": "openshift-kube-apiserver",
    "creationTimestamp": null,
    "labels": {
      "apiserver": "true",
      "app": "openshift-kube-apiserver",
      "revision": "2"
    },
    "annotations": {
      "kubectl.kubernetes.io/default-container": "kube-apiserver",
      "target.workload.openshift.io/management": "{\"effect\": \"PreferredDuringScheduling\"}"
    }
  },
  "spec": {
    "volumes": [
      {
        "name": "resource-dir",
        "hostPath": {
          "path": "/etc/kubernetes/static-pod-resources/kube-apiserver-pod-2"
        }
      },
      {
        "name": "cert-dir",
        "hostPath": {
          "path": "/etc/kubernetes/static-pod-resources/kube-apiserver-certs"
        }
      },
      {
        "name": "audit-dir",
        "hostPath": {
          "path": "/var/log/kube-apiserver"
        }
      }
    ],
    "initContainers": [
      {
        "name": "setup",
        "image": "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6191e17ae9a6d100e9e62ac3dae2dab4c36a1cddea0c6cc50f95dc466dc2cac3",
        "command": [
          "/usr/bin/timeout",
          "100",
          "/bin/bash",
          "-ec"
        ],
        "args": [
          "echo \"Fixing audit permissions ...\"\nchmod 0700 /var/log/kube-apiserver \u0026\u0026 touch /var/log/kube-apiserver/audit.log \u0026\u0026 chmod 0600 /var/log/kube-apiserver/*\n\nLOCK=/var/log/kube-apiserver/.lock\necho \"Acquiring exclusive lock ${LOCK} ...\"\n\n# Waiting for 15s max for old kube-apiserver's watch-termination process to exit and remove the lock.\n# Two cases:\n# 1. if kubelet does not start the old and new in parallel (i.e. works as expected), the flock will always succeed without any time.\n# 2. if kubelet does overlap old and new pods for up to 130s, the flock will wait and immediate return when the old finishes.\n#\n# NOTE: We can increase 15s for a bigger expected overlap. But a higher value means less noise about the broken kubelet behaviour, i.e. we hide a bug.\n# NOTE: Do not tweak these timings without considering the livenessProbe initialDelaySeconds\nexec {LOCK_FD}\u003e${LOCK} \u0026\u0026 flock --verbose -w 15 \"${LOCK_FD}\" || {\n  echo \"$(date -Iseconds -u) kubelet did not terminate old kube-apiserver before new one\" \u003e\u003e /var/log/kube-apiserver/lock.log\n  echo -n \": WARNING: kubelet did not terminate old kube-apiserver before new one.\"\n\n  # We failed to acquire exclusive lock, which means there is old kube-apiserver running in system.\n  # Since we utilize SO_REUSEPORT, we need to make sure the old kube-apiserver stopped listening.\n  #\n  # NOTE: This is a fallback for broken kubelet, if you observe this please report a bug.\n  echo -n \"Waiting for port 6443 to be released due to likely bug in kubelet or CRI-O \"\n  while [ -n \"$(ss -Htan state listening '( sport = 6443 or sport = 6080 )')\" ]; do\n    echo -n \".\"\n    sleep 1\n    (( tries += 1 ))\n    if [[ \"${tries}\" -gt 10 ]]; then\n      echo \"Timed out waiting for port :6443 and :6080 to be released, this is likely a bug in kubelet or CRI-O\"\n      exit 1\n    fi\n  done\n  #  This is to make sure the server has terminated independently from the lock.\n  #  After the port has been freed (requests can be pending and need 60s max).\n  sleep 65\n}\n# We cannot hold the lock from the init container to the main container. We release it here. There is no risk, at this point we know we are safe.\nflock -u \"${LOCK_FD}\"\n"
        ],
        "resources": {
          "requests": {
            "cpu": "5m",
            "memory": "50Mi"
          }
        },
        "volumeMounts": [
          {
            "name": "audit-dir",
            "mountPath": "/var/log/kube-apiserver"
          }
        ],
        "terminationMessagePolicy": "FallbackToLogsOnError",
        "imagePullPolicy": "IfNotPresent",
        "securityContext": {
          "privileged": true
        }
      }
    ],
    "containers": [
      {
        "name": "kube-apiserver",
        "image": "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:6191e17ae9a6d100e9e62ac3dae2dab4c36a1cddea0c6cc50f95dc466dc2cac3",
        "command": [
          "/bin/bash",
          "-ec"
        ],
        "args": [
          "LOCK=/var/log/kube-apiserver/.lock\n# We should be able to acquire the lock immediatelly. If not, it means the init container has not released it yet and kubelet or CRI-O started container prematurely.\nexec {LOCK_FD}\u003e${LOCK} \u0026\u0026 flock --verbose -w 30 \"${LOCK_FD}\" || {\n  echo \"Failed to acquire lock for kube-apiserver. Please check setup container for details. This is likely kubelet or CRI-O bug.\"\n  exit 1\n}\nif [ -f /etc/kubernetes/static-pod-certs/configmaps/trusted-ca-bundle/ca-bundle.crt ]; then\n  echo \"Copying system trust bundle ...\"\n  cp -f /etc/kubernetes/static-pod-certs/configmaps/trusted-ca-bundle/ca-bundle.crt /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\nfi\n\nexec watch-termination --termination-touch-file=/var/log/kube-apiserver/.terminating --termination-log-file=/var/log/kube-apiserver/termination.log --graceful-termination-duration=15s --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig -- hyperkube kube-apiserver --openshift-config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml --advertise-address=${HOST_IP}  -v=2 --permit-address-sharing\n"
        ],
        "ports": [
          {
            "containerPort": 6443
          }
        ],
        "env": [
          {
            "name": "POD_NAME",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "metadata.name"
              }
            }
          },
          {
            "name": "POD_NAMESPACE",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "metadata.namespace"
              }
            }
          },
          {
            "name": "STATIC_POD_VERSION",
            "value": "2"
          },
          {
            "name": "HOST_IP",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "status.hostIP"
              }
            }
          },
          {
            "name": "GOGC",
            "value": "100"
          }
        ],
        "resources": {
          "requests": {
            "cpu": "265m",
            "memory": "1Gi"
          }
        },
        "volumeMounts": [
          {
            "name": "resource-dir",
            "mountPath": "/etc/kubernetes/static-pod-resources"
          },
          {
            "name": "cert-dir",
            "mountPath": "/etc/kubernetes/static-pod-certs"
          },
          {
            "name": "audit-dir",
            "mountPath": "/var/log/kube-apiserver"
          }
        ],
        "livenessProbe": {
          "httpGet": {
            "path": "livez",
            "port": 6443,
            "scheme": "HTTPS"
          },
          "initialDelaySeconds": 45,
          "timeoutSeconds": 10
        },
        "readinessProbe": {
          "httpGet": {
            "path": "readyz",
            "port": 6443,
            "scheme": "HTTPS"
          },
          "initialDelaySeconds": 10,
          "timeoutSeconds": 10
        },
        "terminationMessagePolicy": "FallbackToLogsOnError",
        "imagePullPolicy": "IfNotPresent",
        "securityContext": {
          "privileged": true
        }
      },
      {
        "name": "kube-apiserver-cert-syncer",
        "image": "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:42843002c92accd28b92ca3b83fd0251d6994cc97082fcf692d34ddb3e2162cf",
        "command": [
          "cluster-kube-apiserver-operator",
          "cert-syncer"
        ],
        "args": [
          "--kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig",
          "--namespace=$(POD_NAMESPACE)",
          "--destination-dir=/etc/kubernetes/static-pod-certs"
        ],
        "env": [
          {
            "name": "POD_NAME",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "metadata.name"
              }
            }
          },
          {
            "name": "POD_NAMESPACE",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "metadata.namespace"
              }
            }
          }
        ],
        "resources": {
          "requests": {
            "cpu": "5m",
            "memory": "50Mi"
          }
        },
        "volumeMounts": [
          {
            "name": "resource-dir",
            "mountPath": "/etc/kubernetes/static-pod-resources"
          },
          {
            "name": "cert-dir",
            "mountPath": "/etc/kubernetes/static-pod-certs"
          }
        ],
        "terminationMessagePolicy": "FallbackToLogsOnError",
        "imagePullPolicy": "IfNotPresent"
      },
      {
        "name": "kube-apiserver-cert-regeneration-controller",
        "image": "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:42843002c92accd28b92ca3b83fd0251d6994cc97082fcf692d34ddb3e2162cf",
        "command": [
          "cluster-kube-apiserver-operator",
          "cert-regeneration-controller"
        ],
        "args": [
          "--kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-cert-syncer-kubeconfig/kubeconfig",
          "--namespace=$(POD_NAMESPACE)",
          "-v=2"
        ],
        "env": [
          {
            "name": "POD_NAMESPACE",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "metadata.namespace"
              }
            }
          }
        ],
        "resources": {
          "requests": {
            "cpu": "5m",
            "memory": "50Mi"
          }
        },
        "volumeMounts": [
          {
            "name": "resource-dir",
            "mountPath": "/etc/kubernetes/static-pod-resources"
          }
        ],
        "terminationMessagePolicy": "FallbackToLogsOnError",
        "imagePullPolicy": "IfNotPresent"
      },
      {
        "name": "kube-apiserver-insecure-readyz",
        "image": "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:42843002c92accd28b92ca3b83fd0251d6994cc97082fcf692d34ddb3e2162cf",
        "command": [
          "cluster-kube-apiserver-operator",
          "insecure-readyz"
        ],
        "args": [
          "--insecure-port=6080",
          "--delegate-url=https://localhost:6443/readyz"
        ],
        "ports": [
          {
            "containerPort": 6080
          }
        ],
        "resources": {
          "requests": {
            "cpu": "5m",
            "memory": "50Mi"
          }
        },
        "terminationMessagePolicy": "FallbackToLogsOnError",
        "imagePullPolicy": "IfNotPresent"
      },
      {
        "name": "kube-apiserver-check-endpoints",
        "image": "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:42843002c92accd28b92ca3b83fd0251d6994cc97082fcf692d34ddb3e2162cf",
        "command": [
          "cluster-kube-apiserver-operator",
          "check-endpoints"
        ],
        "args": [
          "--kubeconfig",
          "/etc/kubernetes/static-pod-certs/configmaps/check-endpoints-kubeconfig/kubeconfig",
          "--listen",
          "0.0.0.0:17697",
          "--namespace",
          "$(POD_NAMESPACE)",
          "--v",
          "2"
        ],
        "ports": [
          {
            "name": "check-endpoints",
            "hostPort": 17697,
            "containerPort": 17697,
            "protocol": "TCP"
          }
        ],
        "env": [
          {
            "name": "POD_NAME",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "metadata.name"
              }
            }
          },
          {
            "name": "POD_NAMESPACE",
            "valueFrom": {
              "fieldRef": {
                "fieldPath": "metadata.namespace"
              }
            }
          }
        ],
        "resources": {
          "requests": {
            "cpu": "10m",
            "memory": "50Mi"
          }
        },
        "volumeMounts": [
          {
            "name": "resource-dir",
            "mountPath": "/etc/kubernetes/static-pod-resources"
          },
          {
            "name": "cert-dir",
            "mountPath": "/etc/kubernetes/static-pod-certs"
          }
        ],
        "livenessProbe": {
          "httpGet": {
            "path": "healthz",
            "port": 17697,
            "scheme": "HTTPS"
          },
          "initialDelaySeconds": 10,
          "timeoutSeconds": 10
        },
        "readinessProbe": {
          "httpGet": {
            "path": "healthz",
            "port": 17697,
            "scheme": "HTTPS"
          },
          "initialDelaySeconds": 10,
          "timeoutSeconds": 10
        },
        "terminationMessagePolicy": "FallbackToLogsOnError",
        "imagePullPolicy": "IfNotPresent"
      }
    ],
    "terminationGracePeriodSeconds": 15,
    "hostNetwork": true,
    "tolerations": [
      {
        "operator": "Exists"
      }
    ],
    "priorityClassName": "system-node-critical"
  },
  "status": {}
}
